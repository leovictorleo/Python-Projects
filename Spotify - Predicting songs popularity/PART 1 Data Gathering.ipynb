{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"PART 1 of the code to be submitted.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"SMWZROLy6Oxt"},"source":["#### Environment"]},{"cell_type":"code","metadata":{"id":"EuW5OkSsjOA-"},"source":["import urllib.request\n","from bs4 import BeautifulSoup\n","import requests\n","import json\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","import math\n","import string\n","import datetime\n","\n","import spotipy\n","from spotipy.oauth2 import SpotifyClientCredentials\n","auth_manager = SpotifyClientCredentials('41f67e00313649c0962534596da52a38','2c885133946d4253b92f50e19bcd9308')\n","sp = spotipy.Spotify(auth_manager=auth_manager)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wS_ZC9M16Oxu"},"source":["# PART 1 - DATASET CREATION"]},{"cell_type":"markdown","metadata":{"id":"oMJMOV7w6Oxu"},"source":["### Web scrapping billboard charts\n","\n","We will use __BeautifulSoup__ and __request__ libraries to search for the songs that showed in the Billboard Top 100 charts from 2010 to 2020, scraping from Wikipedia."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"NvhkfC7e6Oxu"},"source":["billboard=pd.DataFrame()\n","for year in range(2009,2021):\n","    url = \"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_\"+str(year) # set page to scrape (iterate with year)\n","    page = urllib.request.urlopen(url) # retrieving the webpage\n","    soup = BeautifulSoup(page, \"lxml\") # import soup\n","    all_tables = soup.find_all(\"table\") # find tables in the webpage\n","    chart = soup.find('table', class_='wikitable sortable') # find table of interest - top 100 chart\n","    #pull out the data from the charts\n","    A=[]\n","    B=[]\n","    C=[]\n","    # append the cells for each column\n","    for row in chart.findAll('tr'):\n","        cells=row.findAll('td')\n","        if len(cells)==3:\n","            A.append(cells[0].find(text=True))\n","            B.append(str(cells[1]).split('title=\"')[1].split('\">')[1].split('</a>')[0])\n","            C.append(cells[2].find(text=True))\n","    df=pd.DataFrame(A,columns=['Number'])\n","    df['title']=B\n","    df['artist']=C\n","    df['year']=year\n","    print(\"Retrieving\", url)\n","    print(\"Singles retrieved:\", df.shape[0])\n","    # append the yearly table to the final table\n","    billboard = billboard.append(df)\n","billboard.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wd7nHjt46Oxu"},"source":["billboard.to_csv(\"billboard.csv\", index=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpNIPqnDD0zg"},"source":["### Get billboard songs from Spotify\n","\n","Using the search function from the __Spotipy__ library, we will search for the billboard songs available on Spotify. Because there are multiple tracks corresponding to the same song, we will retrieve the track with top *popularity* (most played). *Popularity* is a Spotify engineered feature that accounts for the number of times a track is played."]},{"cell_type":"code","metadata":{"id":"bWW9SGJN6Oxv"},"source":["def getFromSpotify(title, artist, year):\n","    sp_list = []\n","\n","    #extract songs by release year\n","    for count in range(math.ceil(2000/50)):\n","        try:\n","            sInfo = sp.search(q='artist:' +str(artist) + ' track:' + title + ' year:' + str(year-1) + \"-\" + str(year),\n","                              type='track',\n","                              limit=1)\n","            for a in sInfo['tracks']['items']:\n","                dict1={}\n","                dict1['name'] = a['name']\n","                dict1['artist_name'] = a['artists'][0]['name']\n","                dict1['track_id'] = a['id']\n","                dict1['track_number'] = a['track_number']\n","                dict1['popularity'] = a['popularity']\n","                dict1['release_date'] = a['album']['release_date']\n","                sp_list.append(dict1)\n","        except Exception as e:\n","            break\n","\n","    return sp_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"TKAAe7f06Oxv"},"source":["for i in range(billboard.shape[0]):\n","    sp_list = getFromSpotify(billboard.iloc[i][\"title\"], billboard.iloc[i][\"artist\"], billboard.loc[i][\"year\"])\n","print(sp_list)\n","billboard.info()\n","print(\"Songs not found:\", sum(df_bb_ids[\"track_id\"].isnull()==True))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfHGHdk66Oxv"},"source":["### Creating a dataset of random hits that have not been on any billboard charts (2010-2020)\n","\n","Now we need a random sample of hits that never been to billboard. This will be done by selecting a random sample of songs as big as possible from Spotify (Spotify API has a limit of 2,000 songs per search). The library __string__ will be used here. Later, duplicates will be eliminated, resulting in a dataset of around 30,000 per year."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"eqy_Q1zH6Oxv"},"source":["# OBSERVATION - This whole code takes a few hours to complete, and may be interrupted due to Spotipy authorization limitations. \n","# The code below represents the complete work implemented for the entire period of analysis (2010-2020).\n","for year in range(2010, 2020):\n","    rows_list = []\n","    for letterdigit in string.printable: \n","        time.sleep(4)\n","        # selecting all songs which name starts with a printable digit (a, b, c, ... 1, 2, 3 etc).\n","        # This was necessary because Spotify API only returns a maximum of 2,000 songs of top popularity, \n","        # by run.\n","        # This code returns the 2,000 top popularity that starts with each digit, and later eliminates duplicates.\n","        # This was an attempt to randomize the songs, while also bringing more than 2,000 songs to compose the dataset.\n","        for count in range(40):\n","            sInfo = sp.search(q=letterdigit+' '+'year:\"'+str(year)+'\"',type='track',limit=50,offset=count*50) # Searching for songs starting with each digit, in that year\n","            for a in sInfo['tracks']['items']:\n","                dict1={}\n","                # retrieving songs' identification data from Spotify\n","                dict1['name'] = a['name'] \n","                dict1['artist_name'] = a['artists'][0]['name']\n","                dict1['track_id'] = a['id']\n","                dict1['track_number'] = a['track_number']\n","                dict1['popularity'] = a['popularity']\n","                dict1['release_date'] = a['album']['release_date']\n","                rows_list.append(dict1)\n","        print(year, letterdigit, len(rows_list))\n","    df1 = pd.DataFrame(rows_list)\n","    df1.drop_duplicates(inplace=True)\n","    df1.to_csv(\"spotify_\"+str(year)+\".csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44yLNKHz6Oxw"},"source":["# Appending all hits to a single dataset\n","no_billboard = pd.read_csv(\"spotify_2010.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date']) \\\n","       .append(pd.read_csv(\"spotify_2011.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2012.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2013.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2014.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2015.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2016.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2017.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2018.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2019.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","       .append(pd.read_csv(\"spotify_2020.csv\", usecols=['name','artist_name','track_id','track_number','popularity','release_date'])) \\\n","          .drop_duplicates()#.to_csv(\"no_billboard.csv\", index=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"GuJ0iH856Oxw"},"source":["# pd.read_csv(\"no_billboard.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jNOEX2ERjof"},"source":["### Get Audio features from Spotify API\n","\n","The next step is importing the songs features from Spotify. We will combine the billboard data to the non-billboard sample and search for the features. As the list of songs to be searched is very large, we are using the library __math__ to divide the dataset into small parts that will be effectivelly searched by the function."]},{"cell_type":"code","metadata":{"id":"fqXb2p_X6Oxx"},"source":["#Combining the two datasets, with the label \"billboard\" (1-song is on billboard, 0-song is not on billboard)\n","billboard[\"billboard\"]=1\n","no_billboard[\"billboard\"]=0\n","all_ids = billboard.append(no_billboard)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4UIzoVbdDlS"},"source":["# Chunking the ids: Spotipy can handle request of upto 100 track ids in one request so,\n","# to reduce the actual number of requests, we will break down the list of ids into sublist of 100 or smaller.\n","chunks = math.floor(len(all_ids)/100)\n","ids_sublists = list(map(lambda x: all_ids[x*100:(x+1)*100], range(chunks))) \n","ids_sublists.append(all_ids[chunks*100:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFxR44sxgYoR"},"source":["# OBSERVATION - This whole code takes a few hours to complete, and may be interrupted due to Spotipy authorization limitations. \n","# The code below represents the complete work implemented for the entire period of analysis (2010-2020).\n","features = list(map(lambda id_chunks: sp.audio_features(id_chunks),ids_sublists))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0cxSxEUjW-Q"},"source":["# If some songs didn't have a valid spotify ID or can't generate a valid response for any reason we need to filter them out.\n","feature_dicts = [item for sublist in features for item in sublist]\n","features_found = list(filter(lambda f: type(f) == dict, feature_dicts))\n","len(features_found)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epQNZCM6l0Db"},"source":["features_df = pd.DataFrame(features_found)\\\n","                .drop_duplicates(subset='id', keep='first')\\\n","                .rename(columns={'id':'track_id'})\n","features_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1V4bMJdMZMp"},"source":["# Combining songs data to new features data\n","data = pd.merge(df, features_df, on='track_id',  how='inner')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3JsnwyJGyj5G"},"source":["### Extract Release Date for songs from Spotify\n","\n","Here, we are retrieving information about the song release date. The only release date available on Spotify is the album release date - this will be used as the track release date.\n","\n","Note: The token needs to be re-initialized when the search is being done using: https://developer.spotify.com/documentation/web-api/reference/search/search/"]},{"cell_type":"code","metadata":{"id":"6esCUl7ycINK"},"source":["data['release_date'] = \"\"\n","\n","for index, site in enumerate(data['track_href']):\n","    token = \"BQAyQF2ioqRpzOnMEFbJvor_Cc8E-zxiltL17ZhNLSPajm53hkIMY-yGVij0lxnEGIakQVa6_7fmzMAamJHCxlurfWsY5QQ7ETDGlY5oqCDj4B7TKdsxkv7dHoXgU-lf-NrSHbrdl4vH-ubJ0WSKELtlVRA_mB5XYS3qTdRivdj8\"\n","    header = {'access_token': token}\n","    if data.at[index, 'release_date']==\"\":\n","        time.sleep(0.2)\n","        result = requests.get(site, header)\n","        data = pd.json_normalize(json.loads(result.content))\n","        try:\n","            data.at[index,'release_date'] = data['album.release_date'][0]\n","        except:\n","            data.at[index,'release_date'] = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZuQW0uMfB7SP"},"source":["def is_date(string, format=\"%Y-%m-%d\"):\n","    try: \n","        datetime.datetime.strptime(string, format)\n","        return True\n","    except ValueError:\n","        return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2QJs0bND_O7"},"source":["data['release_year'] = data['release_date'].str[:4]\n","data['release_month'] = 0\n","data['release_day'] = 0\n","data['release_week'] = 0\n","\n","for index, rd in enumerate(data['release_date']):\n","    if is_date(rd):\n","        data.at[index, 'release_month'] = rd[5:7]\n","        data.at[index, 'release_day'] = rd[8:10]\n","        r_date = datetime.datetime.strptime(rd, format)\n","        data.at[index, 'release_week'] = r_date.isocalendar()[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qih58R9Rk2nb"},"source":["data_dates = df_bb[['track_id','release_date','release_year','release_month','release_day', 'release_week']].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FYI4e_vngGo"},"source":["### Finding songs' musical genres\n","\n","Another piece of information we retrieved from Spotify is the music genres of each song. Each song can have multiple genres. Once again, the genres are not defined by song/track, but by artist or album. Here, we are going to import the artist genres. "]},{"cell_type":"code","metadata":{"id":"Gs0TBvcInyb1","scrolled":true},"source":["# Deduplicating the artists names, to make the code faster\n","artists = list(map(lambda x: str(x), data['artist_name'].unique()))\n","artists = artists.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"V-vM3qmSof9k"},"source":["# This function requests Spotify for each artist's list of genres\n","def requestGenre(name):\n","    gen = ''\n","    try:\n","        artists_found = sp.search(name, type='artist')['artists']['items']\n","        match = list(filter(lambda a: a['name'] == name, artists_found))\n","        gen = '_'.join(match[0]['genres'])\n","        print(\"Processed For - \"+name)\n","    except Exception as e:\n","        print(\"Not Found - \"+name)\n","    return {'artist_name':name,'genres':gen}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"-z_fFBcu6Oxz"},"source":["# OBSERVATION - This whole code takes a few hours to complete, and may be interrupted due to Spotipy authorization limitations. \n","# The code below represents the complete work implemented for the entire period of analysis (2010-2020).\n","genre_list = list(map(requestGenre, artists))\n","df_genre = pd.DataFrame(genre_list)\n","# df_genre.to_csv(folder+\"genre_by_artist.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQQk_85sLrP8"},"source":["# Now that we have the data on genre (from artists) and songs, we can join these files based on the artist name.\n","df_merged = df.merge(df_reread,how=\"inner\",on=\"artist_name\").drop([\"Unnamed: 0_x\",\"Unnamed: 0_y\"], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHqpskfVNJd5"},"source":["df_merged_final.to_csv(\"/content/drive/MyDrive/v2_with_genre.csv/v2_with_genre.csv\")"],"execution_count":null,"outputs":[]}]}